\subsection{Dettagli implementativi dell'applicativo}

Ora che e' chiara la struttura del progetto si puo' procedere con la descrizione del
codice e delle relative funzionalita'. Per fare cio' e' stato scelto come linguaggio
di programmazione \textbf{Golang} per la sua semplicita' d'uso, per i thread in user space
meglio note come \textbf{goroutine} e per i suoi channel di comunicazione.
Per non dilungarsi nella inutile spiegazione di come funziona il protocollo RAFT d'ora in avanti
si assumera' che il lettore abbia conoscenza dell'argomento. In caso contrario si invita
a leggere il paper di riferimento.
\subsubsection{Obiettivi}
Avendo usato gli elementi precendentemente citati per delineare la struttura del cluster tutto
cio' che deve fare questa parte del progetto e':
\begin{itemize}
    \item implementare il protocollo RAFT per sincronizzare i nodi
    \item soddisfare le richieste inviate dai client distinguendole da quelle dei nodi
    \item riconoscere se e quando viene aggiunto un nodo nella rete
    \item implementare il cambio di configurazione secondo i criteri del protocollo RAFT
    \item riconoscere se e quando un nodo non e' piu' attivo
    \item permettere il soddisfaciemento di una o piu' delle richieste citate in contemporanea 
        senza implementare spinlock
\end{itemize}
% Sezione vuota per scaletta
%TODO: ingloberei questa sotto sezione alla sezione Obiettivi

\subsubsection{Funzionamento}
Il codice e' stato strutturato per essere diviso in due fasi: 
\begin{itemize}
    \item \textbf{Inizializzazione}: dove vengono caricati tutti gli ip scoperti dal deamon
        \textbf{discovery.service} (quello del nodo stesso e quelli dei nodi attualmente presenti 
        nella rete), la directory dove salvare i dati del filesystem distribuito. Fatto 
        il nodo tenta di instanziare una connessione con gli altri nodi scoperti dal dameon e 
        ifine instanzia una goroutine per l'accettazione di nuove connessioni in ingresso che 
        verranno poi smistate in base all'ip di provenienza. Usando questa struttura si garantisce
        che ogni nodo creera' una connessione, se possibile, con ogni altro nodo nella rete. 
        E' importante ricordare che instaurare una connessione non implica appartenere 
        alla stessa configurazione. Inoltre in questa fase fengono instanziati
        dei clock necessari per l'implementazione del protocollo RAFT.
        E' importante sottolineare che per ogni connessione accettata verra' creata una 
        goroutine responsabile di ricevere i messaggi dal nodo di riferimento.
    \item \textbf{Loop}: In questa fase viene eseguito un loop con una chiamata bloccante che 
        rilascia la \textbf{CPU} fino a che non si verifica una delle tre condizioni:
        \begin{itemize}
            \item il nodo riceve una richiesta RPC
            \item scatta il timer responsabile dell'elezione di un nuovo leader
            \item scatta il timer che indica di dover inviare un nuovo hearthbit
        \end{itemize}
        E' importante puntualizzare che ogni qualvolta si dovesse verificare una delle condizioni
        verra' creata una goroutine per soddisfare la richiesta liberando il main loop.
        Facendo cio' si fornisce un miglior tempo di risposta garentendo inoltre la disponibilita' 
        del servizio.
\end{itemize}
La spiegazione del codice continuera' indagando i tre casi del loop appena citati spiegando i moduli 
utilizzati man mano. Dove ognuna delle condizioni citate consiste nella ricezione di un messaggio
in uno specifico channel.

\paragraph{il nodo riceve una richiesta RPC}
Come gia' accennato in precedenza ad ogni nodo viene assegnata una goroutine responsabile di
ricevere messaggi da quella connessione. Quando cio' accade l'intero messaggio viene deserializzato
con \textbf{Protobuf}.
Dopo aver estratto il messaggio, la procedura ricava l'ip del mittente, informazione necessaria per 
sapere a chi inviare una risposta se necessario,
viene eseguita l'RPC, si verifica se la procedura ha ritornato un risposta da inviare al mittente,
si invia la risposta in caso e si notifica il completamento su un channel dedicato 
per quel messaggio. Quest'ultima parte e' stata introdotta per garantire che un nodo non possa 
saturare il leader di messaggi monopolizzandolo. Questa scelta comporta che il leader non accettera' 
altri messaggi da uno stesso nodo fino a che il precedente non sara' stato trattato. Siamo a 
conoscenza che questo sia un grande limite ma e' stato il modo migliore che siamo riusciti 
a trovare per garantire la correttezza dell'esecuzione senza introdurre race condition nell'esecuzione
dei messaggi di un nodo.

\subsubsection{scatta il timer responsabile dell'elezione di un nuovo leader}
Non appena il timer per l'elezione segnala nel proprio channel la sua scadenza, il main loop avvia 
una goroutine startElection che segnala l'inizio di una nuuova elezione e resetta alcune variabili 
interne, come il numero di sostenitori e dei non sostenitori. In questo modo, si prepara il terreno 
per una nuova competizione per la leadership.
Successivamente, startElection incrementa il termine corrente del nodo, indicando che il nodo sta 
cercando di diventare il leader in un nuovo ciclo di elezione. Questa operazione è fondamentale per 
garantire che ogni nodo possa riconoscere il progresso delle elezioni e sapere che il nodo che sta 
tentando di diventare leader ha un "termine" più alto rispetto agli altri nodi, il che è un 
requisito essenziale per la validità della richiesta di voto.
Un altro passo importante è il voto per se stesso. Il nodo si autovota, esprimendo così la sua 
intenzione di diventare leader. Questo è un passaggio fondamentale nel protocollo Raft, dove ogni 
nodo deve cercare di ottenere il consenso degli altri nodi.
Dopo essersi autovotato, il nodo crea un messaggio RPC di richiesta di voto, preparandosi a 
inviarlo agli altri nodi del cluster. Questo messaggio contiene informazioni sullo stato corrente 
del nodo e la sua richiesta di voto, e viene codificato in un formato che può essere compreso 
dagli altri nodi.
Infine, startElection invia questa richiesta di voto a tutti i nodi nel cluster. Utilizzando una 
goroutine per ogni invio, la funzione si assicura che le richieste vengano inviate in parallelo, 
ottimizzando così il tempo di attesa e aumentando le probabilità di ricevere risposte rapide.

\subsubsection{scatta il timer che indica di dover inviare un nuovo heartbit}
Allo scadere del timer per l'heartbit, un'ulteriore goroutine viene lanciata e attraversa tutti 
gli indirizzi IP dei nodi elencati nella configurazione. Per ogni indirizzo IP, la funzione 
verifica che il nodo esista (ossia esiste nella subnet) e se il nodo è stato trovato, la funzione 
procede a ottenere lo stato attuale di quel nodo. Questo metodo è vitale perché fornisce 
informazioni aggiornate, come l'indice della prossima voce di log da elaborare. 
Con il nodo trovato e le informazioni recuperate, la funzione determina se il nodo richiede nuove 
voci di log. Se l'indice della prossima voce (nextIndex) è inferiore al numero totale di voci di 
log disponibili, significa che ci sono aggiornamenti da inviare. 
In questo caso, viene creato un messaggio di tipo AppendEntryRpc.
Questa creazione di messaggi è fondamentale per garantire che i follower siano sempre allineati 
con il leader. Se, invece, non ci sono nuove voci da inviare, viene generato un messaggio di 
heartbeat generico che funge da segnale di vita, dimostrando che il leader è ancora attivo e 
operativo.
Una volta creato il messaggio di heartbeat, la funzione lo codifica in un formato che può essere 
trasmesso sulla rete.
Infine, il messaggio codificato viene inviato al nodo. 
Questo viene ripetuto per tutti gli elementi presenti nella configurazione.

\subsubsection{Funzionamento}
% Sezione vuota per scaletta
All'avvio, il nodo legge la configurazione, che include l'indirizzo IP dei nodi pesenti e del nodo stesso. Viene quindi creato un server Raft che rappresenta il nodo stesso. Questa configurazione è fondamentale per definire la 
rete di nodi Raft che formeranno il cluster.
Una volta configurato, il server avvia il nodo Raft, che si mette in ascolto per comunicazioni e richieste. A questo punto, ogni nodo può interagire con gli altri nel cluster, comunicando attraverso RPCs (Remote Procedure Calls).

\textbf{Comunicazione tra Nodi}\\
Una parte cruciale del flusso è la comunicazione tra nodi, che avviene principalmente attraverso due fasi: replicazione del log e elezioni del leader. Queste interazioni vengono gestite tramite vari tipi di RPC definiti 
nel progetto.
Quando un nodo leader deve replicare le voci del log, invia un'RPC AppendEntryRpc ai nodi follower. I follower, una volta ricevuta la richiesta, e, se la richiesta è valida e il log viene replicato correttamente, i follower 
rispondono confermando la replica.
Durante il processo di elezione del leader, i nodi inviano una richiesta di voto con l'RPC RequestVoteRPC. I nodi che ricevono questa richiesta processano la decisione di votare o meno per il candidato leader, assicurandosi 
che i requisiti per il voto (come la consistenza del log) siano soddisfatti.

\textbf{Processo di elezione}\\
Il sistema Raft monitora costantemente la presenza di un leader attivo. Quando un nodo non riceve messaggi di "heartbeat" (AppendEntry) dal leader entro un determinato timeout, questo evento segnala che il leader potrebbe essere 
inaccessibile o non funzionante. Ogni nodo follower mantiene un proprio timer, e se scade senza ricevere comunicazioni dal leader, quel nodo considera il leader inattivo e transita in uno stato di candidate.
In questo stato, il nodo invia richieste di voto agli altri nodi del cluster attraverso l'RPC RequestVoteRPC. Il nodo candidato cercherà di ottenere voti sufficienti per diventare leader. Durante questa fase, 
ogni nodo che riceve una richiesta di voto valuta se concedere il proprio voto al candidato, basandosi sulla propria situazione di stato e log.
Se il candidato riceve voti dalla maggioranza dei nodi, assume il ruolo di leader e comincia immediatamente a inviare messaggi AppendEntryRpc ai follower per confermare la propria leadership e mantenere i log sincronizzati. 
Se invece nessun candidato ottiene la maggioranza, viene avviato un nuovo ciclo elettorale fino a quando non viene selezionato un leader. 

\textbf{Replicazione dei Log, Commit e applicazione allo stato della macchina}\\
Uno dei flussi operativi principali riguarda la gestione del log, che è il meccanismo attraverso cui Raft garantisce la consistenza dei dati nei nodi. Il log è gestito da due componenti separate: una chiamata leader e l'altra 
chiamata slave e, come descritto nel paragrafo precedente, la prima ha permessi di scrittura, mentre la seconda di sola lettura.
Quando un leader riceve un nuovo comando, lo aggiunge al suo log interno e, a questo punto, informa le configurazioni attive che ha aggiunto una nuova voce al registro. Dopodiché, ogni configurazione invia un messaggio 
AppendEntryRPC ai nodi corrispondenti.
I follower ricevono questo messaggio, lo aggiungono al loro log, e rispondono al leader. 
Quando il leader riceve una risposta AppendEntryResponse da ciascun nodo, aggiorna i rispettivi indici: nextIndex e matchIndex, mantenendo così allineati i nodi con lo stato corrente del registro. Successivamente,
notifica l'avvenuta aggiunta di una entry al log system attraverso canali asincroni (NotifyAppendEntryC) definiti nelle implementazioni del log. Il leader invia un commit alla maggior parte dei nodi, e i follower seguono l'ordine di commit. 
Quando le voci vengono committate, esse vengono applicate allo stato condiviso del sistema.
Il canale ReturnValue nel log permette di gestire i risultati delle operazioni in maniera asincrona, in modo che il sistema possa continuare ad operare senza attendere che ogni operazione venga completata in modo sincrono.

\textbf{Gestione delle configurazioni}\\
L'aspetto più importante dell'intero cluster è la gestione delle configurazioni. Il sistema prevede due configurazioni distinte: quella corrente e quella nuova. La presenza simultanea di entrambe indica che il cluster si 
trova in uno stato di transizione da una configurazione all'altra.\\
Quando il leader riceve una richiesta da un client per applicare una nuova configurazione, che include un elenco di nodi, aggiorna l'elenco, imposta la nuova configurazione e informa i nuovi nodi che non sono ancora autorizzati
a votare. Il leader inizia quindi a replicare il proprio log, aggiornando i nuovi nodi follower.\\
Durante questa procedura, potrebbe accadere che uno dei nuovi nodi non venga trovato a causa della sua assenza nella subnet. In tal caso, le informazioni su quel nodo vengono memorizzate e aggiornate in seguito. Infine, 
il sistema esegue controlli periodici per verificare se il log di ciascun nodo è sincronizzato; quando un nodo risulta aggiornato, il leader gli concede il diritto di voto.

\subsubsection{Limiti}
% Sezione vuota per scaletta
Anche se il nostro sistema funziona come descritto nel documento (citare documento), presenta un grave difetto. La Figura 3 illustra la parte del sistema principalmente coinvolta nel processo di \textit{commit} degli indici.
\\
\begin{lstlisting}[language=Go]
func (c *commonMatchImp) 
    checkUpdateNewMatch(sub *substriber) { 
  var halfNodeNum = c.numNodes/2 
  for c.run { 
    var newMatch = <-sub.Snd 
    if newMatch > c.commonMatchIndex && 
        sub.Trd < newMatch { 
      c.numStable++ 
      if c.numStable > uint(halfNodeNum) {
        if c.commitEntryC != nil {
          c.commitEntryC <- c.commonMatchIndex
        } 
        c.commonMatchIndex++
        c.numStable = 1
      } 
    } 
    sub.Trd = newMatch
  } 
}
\end{lstlisting}
Il problema deriva da una sezione critica del codice a cui accedono contemporaneamente più Goroutine senza alcun meccanismo di controllo dell'accesso. In particolare, è possibile che una Goroutine 
superi il controllo iniziale ed esegua le operazioni previste, e che subito dopo una seconda Goroutine superi lo stesso controllo. A questo punto, però, la prima Goroutine ha già modificato i valori condivisi all'interno del 
corpo dell'istruzione if, il che significa che la seconda Goroutine opera su valori non aggiornati, invalidando di fatto la condizione del guard. Anche se abbiamo eseguito numerosi test (che riconosciamo essere insufficienti 
per dimostrare l'assenza di bug) e abbiamo trovato difficile riprodurre le condizioni necessarie per far emergere questa condizione di race, non abbiamo ancora osservato questo problema nella pratica.
