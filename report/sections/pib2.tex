\subsection{Dettagli implementativi dell'applicativo}

Ora che e' chiara la struttura del progetto si puo' procedere con la descrizione del
codice e delle relative funzionalita'. Per fare cio' e' stato scelto come linguaggio
di programmazione \textbf{Golang} per la sua semplicita' d'uso, per i thread in user space
meglio note come \textbf{goroutine} e per i suoi channel di comunicazione.
Per non dilungarsi nella inutile spiegazione di come funziona il protocollo RAFT d'ora in avanti
si assumera' che il lettore abbia conoscenza dell'argomento. In caso contrario si invita
a leggere il paper di riferimento.
\subsubsection{Obiettivi}
Avendo usato gli elementi precendentemente citati per delineare la struttura del cluster tutto
cio' che deve fare questa parte del progetto e':
\begin{itemize}
    \item implementare il protocollo RAFT per sincronizzare i nodi
    \item soddisfare le richieste inviate dai client distinguendole da quelle dei nodi
    \item riconoscere se e quando viene aggiunto un nodo nella rete
    \item implementare il cambio di configurazione secondo i criteri del protocollo RAFT
    \item riconoscere se e quando un nodo non e' piu' attivo
    \item permettere il soddisfaciemento di una o piu' delle richieste citate in contemporanea 
        senza implementare spinlock
\end{itemize}
% Sezione vuota per scaletta
%TODO: ingloberei questa sotto sezione alla sezione Obiettivi

\subsubsection{Funzionamento}
Il codice e' stato strutturato per essere diviso in due fasi: 
\begin{itemize}
    \item \textbf{Inizializzazione}:in questa fase vengono caricati tutti gli ip scoperti dal deamon
        \textbf{discovery.service} (quello del nodo stesso e quelli dei nodi attualmente presenti 
        nella rete) e la directory dove salvare i dati del filesystem distribuito. Fatto cio'
        il nodo tenta di instanziare una connessione con ogni indirizzo ip scoperto.
        Inoltre in questa fase fengono instanziati dei clock necessari per l'implementazione 
        del protocollo RAFT anche se rimangono disattivati fino a che il nodo non appartiene a una
        configurazione
    \item \textbf{Loop}: In questa fase viene eseguito un loop con una chiamata bloccante che 
        rilascia la \textbf{CPU} fino a che non si verifica una delle tre condizioni:
        \begin{itemize}
            \item il nodo riceve una richiesta RPC
            \item scatta il timer responsabile dell'elezione di un nuovo leader
            \item scatta il timer che indica di dover inviare un nuovo hearthbit
        \end{itemize}
        E' importante puntualizzare che ogni qualvolta si dovesse verificare una delle condizioni
        verra' creata una goroutine per soddisfare la richiesta liberando il main loop.
        Facendo cio' si fornisce un miglior tempo di risposta garentendo inoltre la disponibilita' 
        del servizio.
\end{itemize}
La spiegazione del codice continuera' indagando come vengono instaurate nuove connessioni 
al di fuori della fase di inizializzazione, come un nodo riconosce di appartenere ad una specifica
configurazione e i tre casi del loop appena citati spiegando i moduli utilizzati man mano. 
Dove ognuna delle condizioni citate consiste nella ricezione di un messaggio in uno specifico 
channel.

\paragraph{Instaurazione di una nuova connessione}
Come accennato sopra, nella fase di inizializzazione ogni nodo cerca di connettersi a tutti i
nodi scoperti dal daemon dello stesso. 
Dopodichè viene lanciata un goroutine che rimane in ascolto di nuove connessioni e 
ogni volta che ne arriva una nuova, il nodo 
controlla l'indirizzo IP, lo distingue tra indirizzo "interno" (nodo) ed "esterno" (client),
lancia una goroutine per ciascuna di queste categorie e, infine, aspetta di ricevere messaggi 
da queste connessioni. \\
La distinzione delle richieste avviene guardando la provenienza della richiesta: 
\begin{itemize}
    \item 192.168.2.X: nodo esterno (client): se il nodo che riceve la richiesta dal client e' il
        server viene servito, se e' un follower ritorna al client l'indirizzo del master 
        da conttattare.
    \item 10.0.0.X: nodo interno: viene salvata la connessione nella memoria del nodo se non e'
        gia' presente
\end{itemize}
Trammite questo sistema ogni nuovo nodo interno comunica a tutti 
i nodi attualmente esistenti la sua esistenza e se e' gia' presente nella rete verra' contattato 
dai nuovi nodi instaurando cosi' una connessione.

\paragraph{Instaurazione delle connessione tra i nodi e appartenenza ad una configurazione}
All'inizio ogni nodo attende che gli venga comunicato se appartiane a una qualche configurazione.
Cio' puo' accadere in diversi modi:
\begin{itemize}
    \item l'attuale master instaura una connesione con il nodo seguente e gli invia un 
        AppendEntry con la configurazione di riferimento. 
        Il nodo diventa follower e applica l'AppendEntry ricevuta con la configurazione del 
        cluster attiva

    \item richiesta dall'amministratore di sistema: l'operatore invia un messaggio a quel nodo dove 
        gli specifica la configurazione di appartenenza. Quando cio' accade il nodo diventa master.
        Questa situazione si verifica solamente nella fase di creazione di un nuovo cluster 
        ed e' necessaria per definire un primo master che dia il via al servizio.
\end{itemize}
Quando si verifica una delle due situazioni i timer precedentemente disabilitati vengono attivati.

\paragraph{il nodo riceve una richiesta RPC}
Come gia' accennato in precedenza ad ogni nodo viene assegnata una goroutine responsabile di
ricevere messaggi da quella connessione. Quando cio' accade l'intero messaggio viene deserializzato
con \textbf{Protobuf}.
Dopo aver estratto il messaggio, la procedura ricava l'ip del mittente, informazione necessaria per 
sapere a chi inviare una risposta se necessario,
viene eseguita l'RPC, si verifica se la procedura ha ritornato un risposta da inviare al mittente,
si invia la risposta in caso e si notifica il completamento su un channel dedicato 
per quel messaggio. Quest'ultima parte e' stata introdotta per garantire che un nodo non possa 
saturare il leader di messaggi monopolizzandolo. Questa scelta comporta che il leader non accettera' 
altri messaggi da uno stesso nodo fino a che il precedente non sara' stato trattato. Siamo a 
conoscenza che questo sia un grande limite ma e' stato il modo migliore che siamo riusciti 
a trovare per garantire la correttezza dell'esecuzione senza introdurre race condition nell'esecuzione
dei messaggi di un nodo.

\subsubsection{scatta il timer responsabile dell'elezione di un nuovo leader}
Non appena il timer per l'elezione segnala nel proprio channel la sua scadenza, il main loop avvia 
una goroutine startElection che segnala l'inizio di una nuuova elezione e resetta alcune variabili 
interne, come il numero di sostenitori e dei non sostenitori. In questo modo, si prepara il terreno 
per una nuova competizione per la leadership.
Successivamente, startElection incrementa il termine corrente del nodo, indicando che il nodo sta 
cercando di diventare il leader in un nuovo ciclo di elezione. Questa operazione è fondamentale per 
garantire che ogni nodo possa riconoscere il progresso delle elezioni e sapere che il nodo che sta 
tentando di diventare leader ha un "termine" più alto rispetto agli altri nodi, il che è un 
requisito essenziale per la validità della richiesta di voto.
Un altro passo importante è il voto per se stesso. Il nodo si autovota, esprimendo così la sua 
intenzione di diventare leader. Questo è un passaggio fondamentale nel protocollo Raft, dove ogni 
nodo deve cercare di ottenere il consenso degli altri nodi.
Dopo essersi autovotato, il nodo crea un messaggio RPC di richiesta di voto, preparandosi a 
inviarlo agli altri nodi del cluster. Questo messaggio contiene informazioni sullo stato corrente 
del nodo e la sua richiesta di voto, e viene codificato in un formato che può essere compreso 
dagli altri nodi.
Infine, startElection invia questa richiesta di voto a tutti i nodi nel cluster. Utilizzando una 
goroutine per ogni invio, la funzione si assicura che le richieste vengano inviate in parallelo, 
ottimizzando così il tempo di attesa e aumentando le probabilità di ricevere risposte rapide.

\subsubsection{scatta il timer che indica di dover inviare un nuovo heartbit}
Allo scadere del timer per l'heartbit, un'ulteriore goroutine viene lanciata e attraversa tutti 
gli indirizzi IP dei nodi elencati nella configurazione. Per ogni indirizzo IP, la funzione 
verifica che il nodo esista (ossia esiste nella subnet) e se il nodo è stato trovato, la funzione 
procede a ottenere lo stato attuale di quel nodo. Questo metodo è vitale perché fornisce 
informazioni aggiornate, come l'indice della prossima voce di log da elaborare. 
Con il nodo trovato e le informazioni recuperate, la funzione determina se il nodo richiede nuove 
voci di log. Se l'indice della prossima voce (nextIndex) è inferiore al numero totale di voci di 
log disponibili, significa che ci sono aggiornamenti da inviare. 
In questo caso, viene creato un messaggio di tipo AppendEntryRpc.
Questa creazione di messaggi è fondamentale per garantire che i follower siano sempre allineati 
con il leader. Se, invece, non ci sono nuove voci da inviare, viene generato un messaggio di 
heartbeat generico che funge da segnale di vita, dimostrando che il leader è ancora attivo e 
operativo.
Una volta creato il messaggio di heartbeat, la funzione lo codifica in un formato che può essere 
trasmesso sulla rete.
Infine, il messaggio codificato viene inviato al nodo. 
Questo viene ripetuto per tutti gli elementi presenti nella configurazione.

\subsubsection{File System abstraction}
Come definito negli obbiettivi il cluster implementa un filesystem distribuito.
In questo contesto, abbiamo ritenuto indispensabile definire un livello di astrazione del file 
system per ogni nodo, al fine di facilitare l'interazione con esso e garantire un'implementazione 
più modulare e gestibile.\\
L'astrazione del file system di ciascun nodo rappresenta un'interfaccia standardizzata che consente di eseguire operazioni sui 
file in modo uniforme, indipendentemente dalle specificità del nodo. Questo approccio consente di mantenere
un elevato grado di coerenza e semplicità nella gestione del file system distribuito.
Il cuore dell'astrazione risiede in un singolo metodo principale, chiamato ApplyLogEntry, che svolge un ruolo centrale nell'elaborazione
delle operazioni sui file. Questo metodo è progettato per accettare una "log entry" come input e 
gestire le seguenti funzioni: il metodo analizza la log entry per identificare il tipo di operazione da eseguire: creazione 
di un nuovo file, scrittura su un file, rinomina di un file, eliminazione di un file; in seguito, procede con 
l'esecuzione dell'operazione corrispondente sul file system del nodo.

\subsubsection{Limiti}
grave difetto. 
Anche se il nostro sistema funziona come descritto nel documento (citare documento), presenta un 
grave difetto. 
La Figura 3 illustra la parte del sistema principalmente coinvolta nel processo di \textit{commit} 
degli indici.
degli indici.
main.c"
\begin{lstlisting}[language=Go]
func (c *commonMatchImp) 
  for c.run { 
    if newMatch > c.commonMatchIndex && 
    ${}}
        sub.Trd < newMatch { 
      c.numStable++ 
      if c.numStable > uint(halfNodeNum) {
        if c.commitEntryC != nil {
          c.commitEntryC <- c.commonMatchIndex
        } 
        c.commonMatchIndex++
        c.numStable = 1
      } 
    } 
    sub.Trd = newMatch
  } 
}
\end{lstlisting}
Il problema deriva da una sezione critica del codice a cui accedono contemporaneamente più 
Goroutine senza alcun meccanismo di controllo dell'accesso. In particolare, è possibile che una Goroutine 
superi il controllo iniziale ed esegua le operazioni previste, e che subito dopo una seconda 
Goroutine superi lo stesso controllo. A questo punto, però, la prima Goroutine ha già modificato i 
valori condivisi all'interno del corpo dell'istruzione if, il che significa che la seconda Goroutine 
opera su valori non aggiornati, invalidando di fatto la condizione della guardia. Anche se abbiamo 
eseguito numerosi test (che riconosciamo essere insufficienti per dimostrare l'assenza di bug) e 
abbiamo trovato difficile riprodurre le condizioni necessarie per far emergere questa condizione di 
race, non abbiamo ancora osservato questo problema nella pratica.
